{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPifxcAoSL5o",
        "outputId": "beddc8ed-30ee-4f2c-9179-f01128772b0c"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install mtcnn\n",
        "!pip install pyngrok\n",
        "!sudo pip install mtcnn\n",
        "!wget 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-windows-amd64.zip'\n",
        "!unzip ngrok-stable-windows-amd64.zip\n",
        "!ngrok authtoken 1ptGlHPRRq0SOuf93xUijgxjHoh_3oVnNMTu52qvyLw9aL2vs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n",
            "Collecting pyngrok\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/4e/a2fe095bbe17cf26424c4abcd22a0490e22d01cc628f25af5e220ddbf6f0/pyngrok-5.0.5.tar.gz (745kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.5-cp37-none-any.whl size=19246 sha256=b6527e50aa09fd564be2e112bc3f1dd2dcdc7c17bd8bf13ae82d054d94c70cad\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/13/64/5ebbcc22eaf53fdf5766b397c1fb17c83f5775fdccf0ea1b88\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.0.5\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "--2021-04-21 11:10:44--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-windows-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.175.47.233, 3.230.235.205, 35.171.215.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.175.47.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13996079 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-windows-amd64.zip’\n",
            "\n",
            "ngrok-stable-window 100%[===================>]  13.35M  3.34MB/s    in 11s     \n",
            "\n",
            "2021-04-21 11:10:56 (1.21 MB/s) - ‘ngrok-stable-windows-amd64.zip’ saved [13996079/13996079]\n",
            "\n",
            "Archive:  ngrok-stable-windows-amd64.zip\n",
            "  inflating: ngrok.exe               \n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYKrFF1R5i9w"
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "# from mtcnn.mtcnn import MTCNN\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "# from trainingfile import get_embedding\n",
        "from funcutils import *\n",
        "# from trainingfile import get_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN20SGqx5al"
      },
      "source": [
        "#Run This cell to train the network\n",
        "# !python trainingfile.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lg2nlkudSOU5",
        "outputId": "cd34d413-fcdb-494c-9f53-3fc2bb1a91a1"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://1d61qqc4dhv-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqbv8dBr2Vat",
        "outputId": "f3ce7c8d-ebae-4227-dc78-80910d75482e"
      },
      "source": [
        "from PIL import Image\n",
        "import pickle\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "#NOW TESTING FOR AN IMAGE\n",
        "new_facenet_model_for_getting_embedding = load_model('/content/drive/MyDrive/NIKHILKUMAR/MiniProject/facenet_keras.h5')\n",
        "def predict_image(filepath):\n",
        "  f=open('/content/drive/MyDrive/NIKHILKUMAR/MiniProject/picklefile.txt','rb')\n",
        "  d=pickle.loads(f.read())\n",
        "  model=d['model']\n",
        "  out_encoder=d['outencoder']\n",
        "  X=list()\n",
        "  faces=list()\n",
        "  testembed=list()\n",
        "  face=extract_face(filepath)\n",
        "  #face.shape\n",
        "  faces.append(face)\n",
        "  X.extend(faces)\n",
        "  Predic=asarray(X)\n",
        "  # load the facenet model\n",
        "  print('Loaded Model')\n",
        "  #Predic.shape\n",
        "  for face_pixels in Predic:\n",
        "    embedding = get_embedding(new_facenet_model_for_getting_embedding , face_pixels)\n",
        "    testembed.append(embedding)\n",
        "  testembed = asarray(testembed)\n",
        "  print(testembed.shape)\n",
        "  # prediction for the face\n",
        "  #samples = expand_dims(testembed, axis=0)\n",
        "  #print(samples.shape)\n",
        "  yhat_class = model.predict(testembed)\n",
        "  yhat_prob = model.predict_proba(testembed)\n",
        "  # get name\n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  print(yhat_prob,yhat_prob[0,class_index]*100<60,class_probability)\n",
        "  print(class_probability)\n",
        "  if class_probability<99.9999:\n",
        "    return 'notfound'\n",
        "  else:\n",
        "    return out_encoder.inverse_transform(yhat_class)[0]\n",
        "  return out_encoder.inverse_transform(yhat_class)[0]\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWel8UaiSRci",
        "outputId": "d0ce028c-8cbe-49fe-84bd-10f30a7ea969"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,flash,request,redirect,url_for,render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "import os\n",
        "import os\n",
        "import socket\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "host = '1.tcp.ngrok.io'\n",
        "port = 12341\n",
        "\n",
        "# Create a TCP socket\n",
        "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "\n",
        "# Bind a local socket to the port\n",
        "server_address = (\"\", port)\n",
        "sock.bind(server_address)\n",
        "sock.listen(1)\n",
        "\n",
        "# Open a ngrok tunnel to the socket\n",
        "\n",
        "app = Flask(__name__,template_folder='/content')\n",
        "# run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "public_url = ngrok.connect(port, \"tcp\", options={\"remote_addr\": \"{}:{}\".format(host, port)})\n",
        "print(\"ngrok tunnel \\\"{}\\\" -> \\\"tcp://127.0.0.1:{}/\\\"\".format(public_url, port))\n",
        "\n",
        "@app.route(\"/\",methods=['GET','POST'])\n",
        "def uploadfile():\n",
        "  if request.method=='POST':\n",
        "    file=request.files['image']\n",
        "    if file:\n",
        "      filename=secure_filename(file.filename)\n",
        "      file.save(filename)\n",
        "      print('image saved')\n",
        "      person_name=predict_image(filepath=f'/content/{filename}')\n",
        "      while True:\n",
        "          connection = None\n",
        "          try:\n",
        "              # Wait for a connection\n",
        "              print(\"\\nWaiting for a connection ...\")\n",
        "              connection, client_address = sock.accept()\n",
        "\n",
        "              print(\"... connection established from {}\".format(client_address))\n",
        "              # name=predict_image(filepath=path)\n",
        "              # Receive the message, send a response\n",
        "              while True:\n",
        "                  data = connection.recv(1024)\n",
        "                  if data:\n",
        "                      print(\"Received: {}\".format(data.decode(\"utf-8\")))\n",
        "\n",
        "                      message = person_name\n",
        "                      print(\"Sending: {}\".format(message))\n",
        "                      connection.sendall(message.encode(\"utf-8\"))\n",
        "                      # sock.close()\n",
        "                      return person_name\n",
        "                  else:\n",
        "                      break\n",
        "          except KeyboardInterrupt:\n",
        "              print(\" Shutting down server.\")\n",
        "\n",
        "              # if connection:\n",
        "                  # connection.close()\n",
        "              # break\n",
        "      # sock.close()\n",
        "      return person_name\n",
        "      # return \"got your image\"\n",
        "  else:\n",
        "    return render_template('sample.html')\n",
        "@app.route('/home')\n",
        "def index():\n",
        "  return \"<h1>this is not home page</h1>\"\n",
        "app.run()\n",
        "sock.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ngrok tunnel \"NgrokTunnel: \"tcp://2.tcp.ngrok.io:15244\" -> \"localhost:12341\"\" -> \"tcp://127.0.0.1:12341/\"\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [21/Apr/2021 11:11:42] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [21/Apr/2021 11:11:44] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image saved\n",
            "Loaded Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [21/Apr/2021 11:14:44] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1, 128)\n",
            "[[9.99999778e-01 4.19278937e-08 1.02651886e-07 2.53299620e-08\n",
            "  5.24309277e-08]] False 99.9999777659331\n",
            "99.9999777659331\n",
            "\n",
            "Waiting for a connection ...\n",
            "... connection established from ('127.0.0.1', 50760)\n",
            "Received: pls send data\n",
            "Sending: ben_afflek\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [21/Apr/2021 11:14:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [21/Apr/2021 11:15:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [21/Apr/2021 11:15:53] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image saved\n",
            "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8a4076a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8a4076a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe8a4076a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [21/Apr/2021 11:16:15] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded Model\n",
            "(1, 128)\n",
            "[[0.11664577 0.10573664 0.38835216 0.36890329 0.02036214]] True 38.83521598185264\n",
            "38.83521598185264\n",
            "\n",
            "Waiting for a connection ...\n",
            "... connection established from ('127.0.0.1', 50880)\n",
            "Received: pls send data\n",
            "Sending: notfound\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [21/Apr/2021 11:16:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [21/Apr/2021 11:18:10] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [21/Apr/2021 11:18:11] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "t=2021-04-21T11:28:42+0000 lvl=warn msg=\"failed to open private leg\" id=f913a6529657 typ=proxy privaddr=localhost:12341 err=\"dial tcp 127.0.0.1:12341: connect: connection timed out\"\n",
            "t=2021-04-21T11:31:37+0000 lvl=warn msg=\"failed to open private leg\" id=19c653622009 typ=proxy privaddr=localhost:12341 err=\"dial tcp 127.0.0.1:12341: connect: connection timed out\"\n",
            "t=2021-04-21T11:32:11+0000 lvl=warn msg=\"failed to open private leg\" id=f34d135b905e typ=proxy privaddr=localhost:12341 err=\"dial tcp 127.0.0.1:12341: connect: connection timed out\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpxS23JBTwVK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
